{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim.models import Word2Vec\n",
    "import gensim\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "import gensim.downloader\n",
    "import numpy as np\n",
    "import string\n",
    "import scipy.spatial\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from utils import * # import utilities\n",
    "data = pd.read_csv('../input/netflix_titles.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the text \n",
    "listed_in $\\rightarrow$genre, description + title $\\rightarrow$ words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['words'] = process_text2(data['title'] + ' ' + data['description'])\n",
    "data['genre'] = process_text2(data['listed_in'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>show_id</th>\n",
       "      <th>type</th>\n",
       "      <th>title</th>\n",
       "      <th>director</th>\n",
       "      <th>cast</th>\n",
       "      <th>country</th>\n",
       "      <th>date_added</th>\n",
       "      <th>release_year</th>\n",
       "      <th>rating</th>\n",
       "      <th>duration</th>\n",
       "      <th>listed_in</th>\n",
       "      <th>description</th>\n",
       "      <th>words</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s1</td>\n",
       "      <td>TV Show</td>\n",
       "      <td>3%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>João Miguel, Bianca Comparato, Michel Gomes, R...</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>August 14, 2020</td>\n",
       "      <td>2020</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>4 Seasons</td>\n",
       "      <td>International TV Shows, TV Dramas, TV Sci-Fi &amp;...</td>\n",
       "      <td>In a future where the elite inhabit an island ...</td>\n",
       "      <td>[future, elite, inhabit, island, paradise, far...</td>\n",
       "      <td>[international, tv, show, tv, drama, tv, fantasy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s2</td>\n",
       "      <td>Movie</td>\n",
       "      <td>7:19</td>\n",
       "      <td>Jorge Michel Grau</td>\n",
       "      <td>Demián Bichir, Héctor Bonilla, Oscar Serrano, ...</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>December 23, 2016</td>\n",
       "      <td>2016</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>93 min</td>\n",
       "      <td>Dramas, International Movies</td>\n",
       "      <td>After a devastating earthquake hits Mexico Cit...</td>\n",
       "      <td>[devastating, earthquake, hit, mexico, city, t...</td>\n",
       "      <td>[drama, international, movie]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s3</td>\n",
       "      <td>Movie</td>\n",
       "      <td>23:59</td>\n",
       "      <td>Gilbert Chan</td>\n",
       "      <td>Tedd Chan, Stella Chung, Henley Hii, Lawrence ...</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>December 20, 2018</td>\n",
       "      <td>2011</td>\n",
       "      <td>R</td>\n",
       "      <td>78 min</td>\n",
       "      <td>Horror Movies, International Movies</td>\n",
       "      <td>When an army recruit is found dead, his fellow...</td>\n",
       "      <td>[army, recruit, found, dead, fellow, soldier, ...</td>\n",
       "      <td>[horror, movie, international, movie]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s4</td>\n",
       "      <td>Movie</td>\n",
       "      <td>9</td>\n",
       "      <td>Shane Acker</td>\n",
       "      <td>Elijah Wood, John C. Reilly, Jennifer Connelly...</td>\n",
       "      <td>United States</td>\n",
       "      <td>November 16, 2017</td>\n",
       "      <td>2009</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>80 min</td>\n",
       "      <td>Action &amp; Adventure, Independent Movies, Sci-Fi...</td>\n",
       "      <td>In a postapocalyptic world, rag-doll robots hi...</td>\n",
       "      <td>[postapocalyptic, world, robot, hide, fear, da...</td>\n",
       "      <td>[action, adventure, independent, movie, fantasy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s5</td>\n",
       "      <td>Movie</td>\n",
       "      <td>21</td>\n",
       "      <td>Robert Luketic</td>\n",
       "      <td>Jim Sturgess, Kevin Spacey, Kate Bosworth, Aar...</td>\n",
       "      <td>United States</td>\n",
       "      <td>January 1, 2020</td>\n",
       "      <td>2008</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>123 min</td>\n",
       "      <td>Dramas</td>\n",
       "      <td>A brilliant group of students become card-coun...</td>\n",
       "      <td>[brilliant, group, student, become, expert, in...</td>\n",
       "      <td>[drama]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  show_id     type  title           director  \\\n",
       "0      s1  TV Show     3%                NaN   \n",
       "1      s2    Movie   7:19  Jorge Michel Grau   \n",
       "2      s3    Movie  23:59       Gilbert Chan   \n",
       "3      s4    Movie      9        Shane Acker   \n",
       "4      s5    Movie     21     Robert Luketic   \n",
       "\n",
       "                                                cast        country  \\\n",
       "0  João Miguel, Bianca Comparato, Michel Gomes, R...         Brazil   \n",
       "1  Demián Bichir, Héctor Bonilla, Oscar Serrano, ...         Mexico   \n",
       "2  Tedd Chan, Stella Chung, Henley Hii, Lawrence ...      Singapore   \n",
       "3  Elijah Wood, John C. Reilly, Jennifer Connelly...  United States   \n",
       "4  Jim Sturgess, Kevin Spacey, Kate Bosworth, Aar...  United States   \n",
       "\n",
       "          date_added  release_year rating   duration  \\\n",
       "0    August 14, 2020          2020  TV-MA  4 Seasons   \n",
       "1  December 23, 2016          2016  TV-MA     93 min   \n",
       "2  December 20, 2018          2011      R     78 min   \n",
       "3  November 16, 2017          2009  PG-13     80 min   \n",
       "4    January 1, 2020          2008  PG-13    123 min   \n",
       "\n",
       "                                           listed_in  \\\n",
       "0  International TV Shows, TV Dramas, TV Sci-Fi &...   \n",
       "1                       Dramas, International Movies   \n",
       "2                Horror Movies, International Movies   \n",
       "3  Action & Adventure, Independent Movies, Sci-Fi...   \n",
       "4                                             Dramas   \n",
       "\n",
       "                                         description  \\\n",
       "0  In a future where the elite inhabit an island ...   \n",
       "1  After a devastating earthquake hits Mexico Cit...   \n",
       "2  When an army recruit is found dead, his fellow...   \n",
       "3  In a postapocalyptic world, rag-doll robots hi...   \n",
       "4  A brilliant group of students become card-coun...   \n",
       "\n",
       "                                               words  \\\n",
       "0  [future, elite, inhabit, island, paradise, far...   \n",
       "1  [devastating, earthquake, hit, mexico, city, t...   \n",
       "2  [army, recruit, found, dead, fellow, soldier, ...   \n",
       "3  [postapocalyptic, world, robot, hide, fear, da...   \n",
       "4  [brilliant, group, student, become, expert, in...   \n",
       "\n",
       "                                               genre  \n",
       "0  [international, tv, show, tv, drama, tv, fantasy]  \n",
       "1                      [drama, international, movie]  \n",
       "2              [horror, movie, international, movie]  \n",
       "3   [action, adventure, independent, movie, fantasy]  \n",
       "4                                            [drama]  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking into the genre, we can see that there are many repeated words in genre. However, 2 \"tv\" will not make great difference to the nature of the entry than 1 \"tv\". Therefore, words in genre should be distinct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[drama, tv, show, fantasy, international]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[drama, international, movie]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[horror, international, movie]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[action, movie, adventure, independent, fantasy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[drama]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              genre\n",
       "0         [drama, tv, show, fantasy, international]\n",
       "1                     [drama, international, movie]\n",
       "2                    [horror, international, movie]\n",
       "3  [action, movie, adventure, independent, fantasy]\n",
       "4                                           [drama]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove repeated words in genre\n",
    "data['genre'] = data['genre'].apply(lambda row: list(set(row)))\n",
    "pd.DataFrame(data['genre']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset from gensim and add some more sentence\n",
    "1. Download gensim dataset *text8* from http://mattmahoney.net/dc/text8.zip, unzip and place it under the \n",
    "2. Add some more sentences from data['words'] to the end of \"text8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7787 more sentences, 18431 distinct words in total.\n"
     ]
    }
   ],
   "source": [
    "# Prepare the \"more sentences\"\n",
    "more_sentences = []\n",
    "words_set = set() # for checking only\n",
    "for i in range(len(data['words'])):\n",
    "    tmp = data['words'].iloc[i]\n",
    "    more_sentences.append(tmp)\n",
    "    words_set.update(tmp)\n",
    "str_total = ''\n",
    "for lst in more_sentences:\n",
    "    str_add = ' '.join(lst)\n",
    "    str_total += str_add\n",
    "print(\"There are {} more sentences, {} distinct words in total.\".format(len(more_sentences),len(words_set)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If text8 is already modified, do Not run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to text8\n",
    "file = '../input/text8/text8'\n",
    "with open(file, 'r',encoding='utf-8') as f:\n",
    "    contents = f.readline().split()\n",
    "print(\"There are {} words \")\n",
    "\n",
    "with open(file, 'a+',encoding='utf-8') as f:\n",
    "    f.write(str_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-11 01:29:58,374 : INFO : loading Word2Vec object from ../model/text8-test.model\n",
      "2021-04-11 01:29:58,451 : INFO : loading wv recursively from ../model/text8-test.model.wv.* with mmap=None\n",
      "2021-04-11 01:29:58,452 : INFO : setting ignored attribute cum_table to None\n",
      "2021-04-11 01:29:58,958 : INFO : Word2Vec lifecycle event {'fname': '../model/text8-test.model', 'datetime': '2021-04-11T01:29:58.958986', 'gensim': '4.0.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.18362-SP0', 'event': 'loaded'}\n"
     ]
    }
   ],
   "source": [
    "# sentences = word2vec.Text8Corpus('../input/text8/text8')\n",
    "# # training\n",
    "# model = word2vec.Word2Vec(vector_size=100, min_count=1)#, window=5, min_count=1, workers=4)\n",
    "# model.build_vocab(sentences)\n",
    "# model.train(sentences, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "# model.save('../model/text8-test.model')\n",
    "model = word2vec.Word2Vec.load(\"../model/text8-test.model\")\n",
    "embeddings = model.wv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the embeddings for words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-11 01:40:15,557 : INFO : loading Word2Vec object from ../model/text8.model\n",
      "2021-04-11 01:40:15,619 : INFO : loading wv recursively from ../model/text8.model.wv.* with mmap=None\n",
      "2021-04-11 01:40:15,624 : INFO : loading vectors from ../model/text8.model.wv.vectors.npy with mmap=None\n",
      "2021-04-11 01:40:15,659 : INFO : loading syn1neg from ../model/text8.model.syn1neg.npy with mmap=None\n",
      "2021-04-11 01:40:15,704 : INFO : setting ignored attribute cum_table to None\n",
      "2021-04-11 01:40:17,606 : INFO : Word2Vec lifecycle event {'fname': '../model/text8.model', 'datetime': '2021-04-11T01:40:17.606093', 'gensim': '4.0.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.18362-SP0', 'event': 'loaded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish the 0 rows\n",
      "finish the 100 rows\n",
      "finish the 200 rows\n",
      "finish the 300 rows\n",
      "finish the 400 rows\n",
      "finish the 500 rows\n",
      "finish the 600 rows\n",
      "finish the 700 rows\n",
      "finish the 800 rows\n",
      "finish the 900 rows\n",
      "finish the 1000 rows\n",
      "finish the 1100 rows\n",
      "finish the 1200 rows\n",
      "finish the 1300 rows\n",
      "finish the 1400 rows\n",
      "finish the 1500 rows\n",
      "finish the 1600 rows\n",
      "finish the 1700 rows\n",
      "finish the 1800 rows\n",
      "finish the 1900 rows\n",
      "finish the 2000 rows\n",
      "finish the 2100 rows\n",
      "finish the 2200 rows\n",
      "finish the 2300 rows\n",
      "finish the 2400 rows\n",
      "finish the 2500 rows\n",
      "finish the 2600 rows\n",
      "finish the 2700 rows\n",
      "finish the 2800 rows\n",
      "finish the 2900 rows\n",
      "finish the 3000 rows\n",
      "finish the 3100 rows\n",
      "finish the 3200 rows\n",
      "finish the 3300 rows\n",
      "finish the 3400 rows\n",
      "finish the 3500 rows\n",
      "finish the 3600 rows\n",
      "finish the 3700 rows\n",
      "finish the 3800 rows\n",
      "finish the 3900 rows\n",
      "finish the 4000 rows\n",
      "finish the 4100 rows\n",
      "finish the 4200 rows\n",
      "finish the 4300 rows\n",
      "finish the 4400 rows\n",
      "finish the 4500 rows\n",
      "finish the 4600 rows\n",
      "finish the 4700 rows\n",
      "finish the 4800 rows\n",
      "finish the 4900 rows\n",
      "finish the 5000 rows\n",
      "finish the 5100 rows\n",
      "finish the 5200 rows\n",
      "finish the 5300 rows\n",
      "finish the 5400 rows\n",
      "finish the 5500 rows\n",
      "finish the 5600 rows\n",
      "finish the 5700 rows\n",
      "finish the 5800 rows\n",
      "finish the 5900 rows\n",
      "finish the 6000 rows\n",
      "finish the 6100 rows\n",
      "finish the 6200 rows\n",
      "finish the 6300 rows\n",
      "finish the 6400 rows\n",
      "finish the 6500 rows\n",
      "finish the 6600 rows\n",
      "finish the 6700 rows\n",
      "finish the 6800 rows\n",
      "finish the 6900 rows\n",
      "finish the 7000 rows\n",
      "finish the 7100 rows\n",
      "finish the 7200 rows\n",
      "finish the 7300 rows\n",
      "finish the 7400 rows\n",
      "finish the 7500 rows\n",
      "finish the 7600 rows\n",
      "finish the 7700 rows\n",
      "There are 934 unknown words.\n",
      "['bheege', 'blackaf', 'pawesome', 'friendbutmarried', 'friendbutmarried', 'realityhigh', 'çarsi', 'ég', 'çok', 'òlòtūré', 'æon', 'şubat', 'elouise', 'makeunders', 'quinglong', 'quinglong', 'sarfarosh', 'orchestrator', 'deewarein', 'türken']\n"
     ]
    }
   ],
   "source": [
    "# Calculate\n",
    "embeddings = model.wv\n",
    "embs_words, unknown_words = cal_emb(data['words'])\n",
    "print(unknown_words[:20])\n",
    "# print(\"Percentage of unknown words: {}%\".format(100*len(unknown_words) / sum([len(sentence) for sentence in sentences])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that unknown words are some uncommon words. Plus the pertentage of unknown words is not high. Therefore, the performance will not be affected much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process other features\n",
    "**country**\\\n",
    "Before: \"Norway, Iceland, United States\"\\\n",
    "After: [\"norway\", \"iceland\", \"united states\"]\\\n",
    "\n",
    "**rating**\\\n",
    "The ratings are groupped into 3 categories, \"M\" for mature, \"G\" for general, \"Y\" for young\\\n",
    "Before: \"TV-Y\",\"TY-G\", etc.\\\n",
    "After: one of \"Y\", \"G\", \"M\"\\\n",
    "\n",
    "**cast**\\\n",
    "Select the first 3 and store in a list\\\n",
    "Before: \"Samuel L. Jackson, John Heard, Kelly Rowan, Clifton Collins Jr., Tony Plana\"\\\n",
    "After: [\"Samuel L. Jackson\", \"John Heard\",\"Kelly Rowan\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process rating and cast\n",
    "mature = ['TV-MA','R','PG-13','TV-14','TV-PG','PG','NC-17']\n",
    "general = ['NR',np.nan,\"G\",\"UR\",'TV-G']\n",
    "young = ['TV-Y','TV-Y7','TV-Y7-FV']\n",
    "mapping = {}\n",
    "# mapping = {1:\"Y\",2:\"G\",3:\"M\"}\n",
    "for item in young:\n",
    "    mapping[item] = \"Y\"\n",
    "for item in general:\n",
    "    mapping[item] = \"G\"\n",
    "for item in mature:\n",
    "    mapping[item] = \"M\"\n",
    "data['rating'] = data['rating'].apply(lambda item: mapping[item])\n",
    "\n",
    "\n",
    "data['cast'] = data['cast'].apply(first_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cast</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[joão miguel, bianca comparato, michel gomes]</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[demián bichir, héctor bonilla, oscar serrano]</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[tedd chan, stella chung, henley hii]</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[elijah wood, john c. reilly, jennifer connelly]</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[jim sturgess, kevin spacey, kate bosworth]</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7782</th>\n",
       "      <td>[imad creidi, antoinette turk, elias gergi]</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7783</th>\n",
       "      <td>[vicky kaushal, sarah-jane dias, raaghav chanana]</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7784</th>\n",
       "      <td>[nasty c]</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7785</th>\n",
       "      <td>[adriano zumbo, rachel khoo]</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7786</th>\n",
       "      <td>[]</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7787 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   cast rating\n",
       "0         [joão miguel, bianca comparato, michel gomes]      M\n",
       "1        [demián bichir, héctor bonilla, oscar serrano]      M\n",
       "2                 [tedd chan, stella chung, henley hii]      M\n",
       "3      [elijah wood, john c. reilly, jennifer connelly]      M\n",
       "4           [jim sturgess, kevin spacey, kate bosworth]      M\n",
       "...                                                 ...    ...\n",
       "7782        [imad creidi, antoinette turk, elias gergi]      M\n",
       "7783  [vicky kaushal, sarah-jane dias, raaghav chanana]      M\n",
       "7784                                          [nasty c]      M\n",
       "7785                       [adriano zumbo, rachel khoo]      M\n",
       "7786                                                 []      M\n",
       "\n",
       "[7787 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['cast','rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3247, 987, 704, 397, 337, 281, 211, 210, 175, 151, 142, 136, 110, 108, 101, 88, 87, 85, 82, 79, 76, 76, 74, 65, 50, 43, 41, 40, 39, 37, 32, 31, 31, 28, 27, 26, 26, 25, 25, 24, 24, 19, 16, 13, 11, 10, 10, 10, 9, 9, 9, 9, 8, 7, 6, 6, 5, 5, 5, 5, 5, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Process country\n",
    "data['country'] = data['country'].apply(split_comma)   \n",
    "country_lst = []\n",
    "from collections import Counter\n",
    "for country in data['country']:\n",
    "    country_lst += country\n",
    "country_summary = dict(Counter(country_lst))\n",
    "country_summary = dict(sorted(country_summary.items(), key = lambda kv:(kv[1], kv[0]),reverse=True))\n",
    "tmp = list(country_summary.values())\n",
    "from matplotlib import pyplot as plt\n",
    "plt.bar(range(len(tmp)),tmp)\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that some countries do not frequently appear. Therefore, we should not waste too many features on these countries.\\\n",
    "1. Select countries appear more than 100 times\n",
    "2. Change other countries and missing entries into \"other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 15 countries selected.\n",
      "Country selected are:  ['united states', 'india', 'united kingdom', 'canada', 'france', 'japan', 'spain', 'south korea', 'germany', 'mexico', 'australia', 'china', 'egypt', 'turkey', 'hong kong']\n"
     ]
    }
   ],
   "source": [
    "selected_country = dict([kv for kv in country_summary.items() if kv[1] >= 100])\n",
    "selected_country_names = selected_country.keys()\n",
    "print(\"There are {} countries selected.\".format(len(selected_country)))\n",
    "print(\"Country selected are: \",list(selected_country_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                             [brazil]\n",
       "1                             [mexico]\n",
       "2                          [singapore]\n",
       "3                      [united states]\n",
       "4                      [united states]\n",
       "5                             [turkey]\n",
       "6                              [egypt]\n",
       "7                      [united states]\n",
       "8                              [india]\n",
       "9                              [india]\n",
       "10                     [united states]\n",
       "11             [poland, united states]\n",
       "12                            [mexico]\n",
       "13                          [thailand]\n",
       "14                     [united states]\n",
       "15                           [nigeria]\n",
       "16                                  []\n",
       "17    [united states, iceland, norway]\n",
       "18                             [india]\n",
       "19                    [united kingdom]\n",
       "Name: country, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def change_country_name(lst):\n",
    "    for i in range(len(lst)):\n",
    "        if lst[i] not in selected_country_names:\n",
    "            lst[i] = 'other'\n",
    "    if len(lst) <= 0:\n",
    "        lst = ['other']\n",
    "    return list(set(lst))\n",
    "\n",
    "# data['country'] = data['country'].apply(change_country_name)\n",
    "data['country'] = data['country'].apply(lambda row: list(set(row)))\n",
    "data['country'].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate feature vectors\n",
    "1. Convert categorical features into one hot representation\n",
    "2. Concatenate categorical features with word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['type', 'title', 'words', 'genre', 'action', 'adventure', 'anime',\n",
       "       'british', 'child', 'classic',\n",
       "       ...\n",
       "       'united states,', 'uruguay', 'vatican city', 'venezuela', 'vietnam',\n",
       "       'west germany', 'zimbabwe', 'G', 'M', 'Y'],\n",
       "      dtype='object', length=157)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert categorical features into one hot representation ('genre','country','rating','type')\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer(sparse_output=True)\n",
    "data2 = data\n",
    "data2 = data[['type', 'title','country', 'rating', 'words', 'genre']]\n",
    "data2 = data2.join(\n",
    "            pd.DataFrame.sparse.from_spmatrix(\n",
    "                mlb.fit_transform(data.pop('genre')),\n",
    "                index=data.index,\n",
    "                columns=mlb.classes_))\n",
    "data2 = data2.join(\n",
    "            pd.DataFrame.sparse.from_spmatrix(\n",
    "                mlb.fit_transform(data2.pop('country')),\n",
    "                index=data.index,\n",
    "                columns=mlb.classes_))\n",
    "\n",
    "data2 = data2.join(\n",
    "            pd.DataFrame.sparse.from_spmatrix(\n",
    "                mlb.fit_transform(data2.pop('rating')),\n",
    "                index=data.index,\n",
    "                columns=mlb.classes_))\n",
    "\n",
    "data2['type'] = data2['type'].apply(lambda row: 1 if row.lower().find('movie')!=-1 else 0)\n",
    "data2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>title</th>\n",
       "      <th>words</th>\n",
       "      <th>genre</th>\n",
       "      <th>action</th>\n",
       "      <th>adventure</th>\n",
       "      <th>anime</th>\n",
       "      <th>british</th>\n",
       "      <th>child</th>\n",
       "      <th>classic</th>\n",
       "      <th>...</th>\n",
       "      <th>united states,</th>\n",
       "      <th>uruguay</th>\n",
       "      <th>vatican city</th>\n",
       "      <th>venezuela</th>\n",
       "      <th>vietnam</th>\n",
       "      <th>west germany</th>\n",
       "      <th>zimbabwe</th>\n",
       "      <th>G</th>\n",
       "      <th>M</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3%</td>\n",
       "      <td>[future, elite, inhabit, island, paradise, far...</td>\n",
       "      <td>[international, tv, show, tv, drama, tv, fantasy]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7:19</td>\n",
       "      <td>[devastating, earthquake, hit, mexico, city, t...</td>\n",
       "      <td>[drama, international, movie]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>23:59</td>\n",
       "      <td>[army, recruit, found, dead, fellow, soldier, ...</td>\n",
       "      <td>[horror, movie, international, movie]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>[postapocalyptic, world, robot, hide, fear, da...</td>\n",
       "      <td>[action, adventure, independent, movie, fantasy]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>[brilliant, group, student, become, expert, in...</td>\n",
       "      <td>[drama]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 157 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   type  title                                              words  \\\n",
       "0     0     3%  [future, elite, inhabit, island, paradise, far...   \n",
       "1     1   7:19  [devastating, earthquake, hit, mexico, city, t...   \n",
       "2     1  23:59  [army, recruit, found, dead, fellow, soldier, ...   \n",
       "3     1      9  [postapocalyptic, world, robot, hide, fear, da...   \n",
       "4     1     21  [brilliant, group, student, become, expert, in...   \n",
       "\n",
       "                                               genre  action  adventure  \\\n",
       "0  [international, tv, show, tv, drama, tv, fantasy]       0          0   \n",
       "1                      [drama, international, movie]       0          0   \n",
       "2              [horror, movie, international, movie]       0          0   \n",
       "3   [action, adventure, independent, movie, fantasy]       1          1   \n",
       "4                                            [drama]       0          0   \n",
       "\n",
       "   anime  british  child  classic  ...  united states,  uruguay  vatican city  \\\n",
       "0      0        0      0        0  ...               0        0             0   \n",
       "1      0        0      0        0  ...               0        0             0   \n",
       "2      0        0      0        0  ...               0        0             0   \n",
       "3      0        0      0        0  ...               0        0             0   \n",
       "4      0        0      0        0  ...               0        0             0   \n",
       "\n",
       "   venezuela  vietnam  west germany  zimbabwe  G  M  Y  \n",
       "0          0        0             0         0  0  1  0  \n",
       "1          0        0             0         0  0  1  0  \n",
       "2          0        0             0         0  0  1  0  \n",
       "3          0        0             0         0  0  1  0  \n",
       "4          0        0             0         0  0  1  0  \n",
       "\n",
       "[5 rows x 157 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 154 categorical features.\n"
     ]
    }
   ],
   "source": [
    "# Convert categorical features with to nparray\n",
    "mat = np.array(data2.drop(columns=['title','words','genre'])).astype(np.int32)\n",
    "print(\"There are {} categorical features.\".format(mat.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7787, 254)\n"
     ]
    }
   ],
   "source": [
    "vectors  = np.concatenate((mat,embs_words),axis = 1)\n",
    "print(vectors.shape)\n",
    "np.save('../data/vectors-show.npy',vectors)\n",
    "vectors = np.load('../data/vectors-show.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_vectors = scale(vectors)\n",
    "cosine_sim = 1 - scipy.spatial.distance.cdist(norm_vectors,norm_vectors, metric='cosine')\n",
    "euclidean_sim = scipy.spatial.distance.cdist(norm_vectors,norm_vectors, metric='euclidean')\n",
    "np.savez('../data/dist-show.npz', cosine_sim, euclidean_sim)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommend\n",
    "**Input**\\\n",
    "title of the movie, dataframe of the original data, name of the distance file(in case there are many distance files, generated from different preprocessing methods)\\\n",
    "**output**\\\n",
    "2 dataframes: one without input and one with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(title,data,dist_name, metric='cosine'):\n",
    "    # load the distance\n",
    "    files = np.load('../data/'+dist_name)\n",
    "    cosine_sim = files['arr_0']\n",
    "    euclidean_sim = files['arr_1']\n",
    "    indices = pd.Series(data.index, index = data['title'].str.lower()).drop_duplicates()\n",
    "    del files # save memory\n",
    "    idx = indices[title.lower()]\n",
    "    if metric =='cosine':\n",
    "        sim_vec = cosine_sim[idx]\n",
    "        # Get the pairwsie similarity scores of all movies with that movie\n",
    "    elif metric == 'euclidean':\n",
    "        sim_vec = euclidean_sim[idx]\n",
    "        \n",
    "    sim_scores = list(enumerate(sim_vec))        \n",
    "    # Sort the movies based on the similarity scores\n",
    "    sorted_sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    res = sorted_sim_scores[:11]\n",
    "    res = [item for item in res if item[0]!=idx]\n",
    "\n",
    "    # Get the movie indices\n",
    "    res_indices = [item[0] for item in res]\n",
    "    res_score = [item[1] for item in res]   \n",
    "    \n",
    "    final_data = data.iloc[res_indices]\n",
    "    final_data.insert(0,'score',res_score)\n",
    "    \n",
    "    with_input_indices = [idx]+res_indices\n",
    "    with_input_score = [1]+res_score \n",
    "    \n",
    "    with_input_data = data.iloc[with_input_indices]\n",
    "    with_input_data.insert(0,'score',with_input_score)\n",
    "    col_lst = [ 'score', 'type', 'title',  'country', 'rating',\n",
    "       'listed_in', 'description']\n",
    "    return final_data[col_lst], with_input_data[col_lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'The Visit'\n",
    "metric='euclidean'\n",
    "final_data,with_input_data = recommend(title, data,dist_name=\"dist-show.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_recommend(sentence, data, metric='cosine',w_genre=0.5):\n",
    "    file = np.load(\"../data/emb_w_g.npz\",allow_pickle=True)\n",
    "    embs_words, embs_genre = file.values()\n",
    "    # embs = embs_words * (1 - w_genre) + embs_genre * w_genre\n",
    "    embs = embs_words\n",
    "    del file\n",
    "    indices = pd.Series(data.index, index = data['title'].str.lower()).drop_duplicates()\n",
    "    embs_sentence, unknown_sentence = cal_emb(process_text2(pd.Series(sentence)))\n",
    "    if metric =='cosine':\n",
    "        sim_vec = cosine_sim_words = metrics.pairwise.cosine_similarity(embs_sentence.reshape(1, -1), embs)\n",
    "\n",
    "        # Get the pairwsie similarity scores of all movies with that movie\n",
    "    elif metric == 'euclidean':\n",
    "        sim_vec = scipy.spatial.distance.cdist(embs_sentence.reshape(1, -1), embs, metric='euclidean')\n",
    "        sim_vec = 1 / np.abs(sim_vec)\n",
    "    \n",
    "    sim_scores = list(enumerate(sim_vec.reshape(-1,1)))\n",
    "    \n",
    "    sorted_sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    res = sorted_sim_scores[:10]\n",
    "\n",
    "    # Get the movie indices\n",
    "    res_indices = [item[0] for item in res]\n",
    "    res_score = [item[1] for item in res]   \n",
    "    \n",
    "    final_data = data.iloc[res_indices]\n",
    "    final_data.insert(0,'score',res_score)\n",
    "    \n",
    "    col_lst = [ 'score',  'type', 'title',  'country', 'rating',\n",
    "       'listed_in', 'description']\n",
    "    return final_data[col_lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-11 01:45:02,128 : INFO : loading Word2Vec object from ../model/text8.model\n",
      "2021-04-11 01:45:02,182 : INFO : loading wv recursively from ../model/text8.model.wv.* with mmap=None\n",
      "2021-04-11 01:45:02,187 : INFO : loading vectors from ../model/text8.model.wv.vectors.npy with mmap=None\n",
      "2021-04-11 01:45:02,227 : INFO : loading syn1neg from ../model/text8.model.syn1neg.npy with mmap=None\n",
      "2021-04-11 01:45:02,263 : INFO : setting ignored attribute cum_table to None\n",
      "2021-04-11 01:45:04,113 : INFO : Word2Vec lifecycle event {'fname': '../model/text8.model', 'datetime': '2021-04-11T01:45:04.113668', 'gensim': '4.0.0', 'python': '3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.18362-SP0', 'event': 'loaded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish the 0 rows\n",
      "There are 0 unknown words.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>type</th>\n",
       "      <th>title</th>\n",
       "      <th>country</th>\n",
       "      <th>rating</th>\n",
       "      <th>listed_in</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3317</th>\n",
       "      <td>[0.8298872811427987]</td>\n",
       "      <td>Movie</td>\n",
       "      <td>Katha</td>\n",
       "      <td>[india]</td>\n",
       "      <td>M</td>\n",
       "      <td>Comedies, Dramas, Independent Movies</td>\n",
       "      <td>Secretly in love with his neighbor, a mild-man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3656</th>\n",
       "      <td>[0.825407415644228]</td>\n",
       "      <td>TV Show</td>\n",
       "      <td>Little Baby Bum: Nursery Rhyme Friends</td>\n",
       "      <td>[united kingdom]</td>\n",
       "      <td>Y</td>\n",
       "      <td>British TV Shows, Kids' TV</td>\n",
       "      <td>Twinkle, Mia, Jacus and the rest of the Nurser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4330</th>\n",
       "      <td>[0.7998429522148135]</td>\n",
       "      <td>Movie</td>\n",
       "      <td>My Little Pony Equestria Girls: Forgotten Frie...</td>\n",
       "      <td>[canada, united states]</td>\n",
       "      <td>Y</td>\n",
       "      <td>Children &amp; Family Movies</td>\n",
       "      <td>School yearbook editor Sunset Shimmer has sudd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2288</th>\n",
       "      <td>[0.7947912627660766]</td>\n",
       "      <td>TV Show</td>\n",
       "      <td>Friends</td>\n",
       "      <td>[united states]</td>\n",
       "      <td>M</td>\n",
       "      <td>Classic &amp; Cult TV, TV Comedies</td>\n",
       "      <td>This hit sitcom follows the merry misadventure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7502</th>\n",
       "      <td>[0.7726338854886157]</td>\n",
       "      <td>Movie</td>\n",
       "      <td>We Are Your Friends</td>\n",
       "      <td>[united kingdom, france, united states]</td>\n",
       "      <td>M</td>\n",
       "      <td>Dramas, Independent Movies, Music &amp; Musicals</td>\n",
       "      <td>An ambitious young DJ who knows how to work a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3522</th>\n",
       "      <td>[0.7681831456462076]</td>\n",
       "      <td>Movie</td>\n",
       "      <td>Lagos Real Fake Life</td>\n",
       "      <td>[]</td>\n",
       "      <td>M</td>\n",
       "      <td>Comedies, International Movies</td>\n",
       "      <td>Two mooching friends vie for the attention of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3583</th>\n",
       "      <td>[0.7681645749209132]</td>\n",
       "      <td>TV Show</td>\n",
       "      <td>LEGO Friends: The Power of Friendship</td>\n",
       "      <td>[denmark]</td>\n",
       "      <td>Y</td>\n",
       "      <td>Kids' TV</td>\n",
       "      <td>Five best friends face adventures side by side...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3061</th>\n",
       "      <td>[0.7673768534104126]</td>\n",
       "      <td>TV Show</td>\n",
       "      <td>Is It Wrong to Try to Pick Up Girls in a Dungeon?</td>\n",
       "      <td>[japan]</td>\n",
       "      <td>M</td>\n",
       "      <td>Anime Series, International TV Shows</td>\n",
       "      <td>Lovable goof Bell Cranel wants an adventure, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>[0.7639739549004583]</td>\n",
       "      <td>Movie</td>\n",
       "      <td>Good and Prosperous</td>\n",
       "      <td>[egypt]</td>\n",
       "      <td>M</td>\n",
       "      <td>Comedies, International Movies</td>\n",
       "      <td>As two jobless brothers search aimlessly for c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5420</th>\n",
       "      <td>[0.7630014996907921]</td>\n",
       "      <td>Movie</td>\n",
       "      <td>Say When</td>\n",
       "      <td>[united states]</td>\n",
       "      <td>M</td>\n",
       "      <td>Comedies, Dramas, Independent Movies</td>\n",
       "      <td>Desperately clinging to her youth, 28-year-old...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     score     type  \\\n",
       "3317  [0.8298872811427987]    Movie   \n",
       "3656   [0.825407415644228]  TV Show   \n",
       "4330  [0.7998429522148135]    Movie   \n",
       "2288  [0.7947912627660766]  TV Show   \n",
       "7502  [0.7726338854886157]    Movie   \n",
       "3522  [0.7681831456462076]    Movie   \n",
       "3583  [0.7681645749209132]  TV Show   \n",
       "3061  [0.7673768534104126]  TV Show   \n",
       "2475  [0.7639739549004583]    Movie   \n",
       "5420  [0.7630014996907921]    Movie   \n",
       "\n",
       "                                                  title  \\\n",
       "3317                                              Katha   \n",
       "3656             Little Baby Bum: Nursery Rhyme Friends   \n",
       "4330  My Little Pony Equestria Girls: Forgotten Frie...   \n",
       "2288                                            Friends   \n",
       "7502                                We Are Your Friends   \n",
       "3522                               Lagos Real Fake Life   \n",
       "3583              LEGO Friends: The Power of Friendship   \n",
       "3061  Is It Wrong to Try to Pick Up Girls in a Dungeon?   \n",
       "2475                                Good and Prosperous   \n",
       "5420                                           Say When   \n",
       "\n",
       "                                      country rating  \\\n",
       "3317                                  [india]      M   \n",
       "3656                         [united kingdom]      Y   \n",
       "4330                  [canada, united states]      Y   \n",
       "2288                          [united states]      M   \n",
       "7502  [united kingdom, france, united states]      M   \n",
       "3522                                       []      M   \n",
       "3583                                [denmark]      Y   \n",
       "3061                                  [japan]      M   \n",
       "2475                                  [egypt]      M   \n",
       "5420                          [united states]      M   \n",
       "\n",
       "                                         listed_in  \\\n",
       "3317          Comedies, Dramas, Independent Movies   \n",
       "3656                    British TV Shows, Kids' TV   \n",
       "4330                      Children & Family Movies   \n",
       "2288                Classic & Cult TV, TV Comedies   \n",
       "7502  Dramas, Independent Movies, Music & Musicals   \n",
       "3522                Comedies, International Movies   \n",
       "3583                                      Kids' TV   \n",
       "3061          Anime Series, International TV Shows   \n",
       "2475                Comedies, International Movies   \n",
       "5420          Comedies, Dramas, Independent Movies   \n",
       "\n",
       "                                            description  \n",
       "3317  Secretly in love with his neighbor, a mild-man...  \n",
       "3656  Twinkle, Mia, Jacus and the rest of the Nurser...  \n",
       "4330  School yearbook editor Sunset Shimmer has sudd...  \n",
       "2288  This hit sitcom follows the merry misadventure...  \n",
       "7502  An ambitious young DJ who knows how to work a ...  \n",
       "3522  Two mooching friends vie for the attention of ...  \n",
       "3583  Five best friends face adventures side by side...  \n",
       "3061  Lovable goof Bell Cranel wants an adventure, a...  \n",
       "2475  As two jobless brothers search aimlessly for c...  \n",
       "5420  Desperately clinging to her youth, 28-year-old...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_recommend(\"hello my friend! Miss you so much\",data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
